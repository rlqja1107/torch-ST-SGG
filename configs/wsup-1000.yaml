
EM:
  MODE: "E"

GLOVE_DIR: /home/public/Datasets/CV/vg_bm
DATA_DIR : /home/public/Datasets/CV/vg_1800
OBJ_PRED_INFO_PATH: "initial_data/obj_pred_info/obj_pred_info_1800.pth"
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: ""
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    RELATION_PROPOSAL_MODEL:
      FOCAL_LOSS_ALPHA: 0.2
      FOCAL_LOSS_GAMMA: 2.0
      EVAL_MODEL_AUC: false
      FIX_MODEL_AT_ITER: 3000
      IGNORE_FOREGROUND_BOXES_PAIRS: false
      METHOD: RelAware_Gumbel # RelAware_Gumbel RelAwareRelFeature
      PAIR_NUMS_AFTER_FILTERING: 128
      PRETRAIN_ITER_RELNESS_MODULE: 2000
      PRETRAIN_RELNESS_MODULE: False
      PRE_CLSER_LOSS: focal_fgbg_norm
      REL_AWARE_PREDICTOR_TYPE: hybrid 
      SET_ON: True
      USE_RELATEDNESS_FOR_PREDICTION_RANKING: false
      USE_SAME_LABEL_WITH_CLSER: false
      VISUAL_FEATURES_ON: True
    FAKE_FREQ_BIAS: True
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 1808                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "MotifPredictor_self_training"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    BGNN_MODULE:
      EDGE_FEATURES_REPRESENTATION: union
      GATING_WITH_RELNESS_LOGITS: false
      GRAPH_HIDDEN_DIM: 512
      GRAPH_ITERATION_NUM: 3
      APPLY_GT: False
      ITERATE_MP_PAIR_REFINE: 3
      RELATION_CONFIDENCE_AWARE: True
      MP_ON_VALID_PAIRS: True
      MP_VALID_PAIRS_NUM: 128
      RELNESS_MP_WEIGHTING: true
      RELNESS_MP_WEIGHTING_SCORE_RECALIBRATION_METHOD: learnable_scaling
      LEARNABLE_SCALING_WEIGHT: (3.12, 0.06)
      SHARE_PARAMETERS_EACH_ITER: false
      SHARE_RELATED_MODEL_ACROSS_REFINE_ITER: false
      SKIP_CONNECTION_ON_OUTPUT: false
      SPLIT_GRAPH4OBJ_REL: false
      REFINE_OBJ: false
      ADD_NON_GT: False
      IS_FULLY_CONNECTED: False
    SELF_TRAIN_MODULE:
      USE_KB: False
      USE_DIFFERENT_STATISTICS: True
      NA_NORMALIZE: False
      SAVE_RESULT: False
      PSEDUO_CONSTRAINT: 3
      DECAY_BATCHWISE: True
      INCREASE_BATCHWISE: True
      THRESHOLD_NAME: "top_k"
      ZERO_INITIAL_VALUE: 0.00001
      ZERO_INITIAL: True
      USE_GSL_OUTPUT: True
      INITIALIZE_THRESHOLD: False
      LAMBDA_COEF: 1.0
      ALPHA: 0.8
      ALPHA_DECAY: 0.4
      FIX_THRESHOLD: False
      UPPER_BOUND: 1.0
      CHANGE_PERIOD: 100
    HETSGG:
      CATEGORY_FILE: VG-SGG-Category_v2
      CLASS_AGG: mean
      FEATURE_UPDATE_STEP: 2
      H_DIM: 128
      NUM_NODETYPES: 3
      NUM_RELATION: 9
      N_BASES: 8
      SCORE_UPDATE_STEP: 2
      USE_REL_PN: false
      VANILLA: false
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("1000DS_VG_VGKB_train",) # 1000DS_VG_VGKB_train, 1000DS_VG_stanford_filtered_with_attribute_train
  VAL: ("1000VG_stanford_filtered_with_attribute_val",)
  TEST: ("1000VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ONLY_ACC: True
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  INFERENCE: "LOGITS"
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed  
WSUPERVISE:
  SPECIFIED_DATA_FILE: "checkpoints/1800/motif/Final_data/yes_ext_yes_int.pk" # "/home/public/Datasets/CV/vg_1800/vg_clip_logits.pk"
  METHOD: "VG_DS"
  DATASET: InTransDataset
  LOSS_TYPE: "attn_bce"
  FL:
    GAMMA: 4.0
    ALPHA: 0.5
    BETA: 0.0
    MAX_VAL: 3
  REG:
    IS_ON: False
    WEIGHT: 1.
    SCALE_FACTOR: 1.
